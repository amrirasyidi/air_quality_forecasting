{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from tqdm.auto import tqdm\n",
    "from dateutil import parser\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helper_functions import epa_taiwan_data_pipeline\n",
    "from models import lstnet_gokul, lstnet_laigoukun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = pathlib.Path(os.getcwd()).parent\n",
    "raw_data_dir = root_dir / \"data/0_raw\"\n",
    "processed_data_dir = root_dir / \"data/1_processed\"\n",
    "experiment_dir = root_dir / \"experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the data\n",
    "- Feature engineering\n",
    "- Turn the data into tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "site_name = \"Banqiao\"\n",
    "columns = [\"SiteEngName\",\"PM2.5\",\"AMB_TEMP\",\"CH4\",'CO',\"NMHC\",\"read_time\"]\n",
    "\n",
    "# import data\n",
    "pm25_df = epa_taiwan_data_pipeline.import_epa_data(site_name=site_name, year=year)[columns]\n",
    "\n",
    "# basic preprocessing\n",
    "pm25_df = epa_taiwan_data_pipeline.standardize_df(pm25_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data length:8760 \n",
      "Train data length:5256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteengname</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>amb_temp</th>\n",
       "      <th>ch4</th>\n",
       "      <th>co</th>\n",
       "      <th>nmhc</th>\n",
       "      <th>read_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399077</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2018-08-07 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399153</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2018-08-07 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399229</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2018-08-07 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399305</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2018-08-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399381</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2018-08-07 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       siteengname  pm2.5  amb_temp  ch4    co  nmhc           read_time\n",
       "399077     Banqiao   11.0      31.4  1.8  0.41  0.13 2018-08-07 19:00:00\n",
       "399153     Banqiao   11.0      30.8  1.8  0.35  0.10 2018-08-07 20:00:00\n",
       "399229     Banqiao   10.0      30.4  1.8  0.31  0.09 2018-08-07 21:00:00\n",
       "399305     Banqiao    8.0      30.2  1.8  0.30  0.08 2018-08-07 22:00:00\n",
       "399381     Banqiao    9.0      29.9  1.8  0.23  0.06 2018-08-07 23:00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = 0.6\n",
    "\n",
    "train_data = pm25_df.iloc[:int(len(pm25_df)*train_split),:]\n",
    "print(f\"All data length:{len(pm25_df)} \\nTrain data length:{len(train_data)}\")\n",
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_columns = ['pm2.5', 'amb_temp', 'ch4', 'co', 'nmhc']\n",
    "\n",
    "for column in normalized_columns:\n",
    "    normalized_column_name = column + '_normalized'\n",
    "    train_data[normalized_column_name] = (train_data[column] - train_data[column].min()) / (train_data[column].max() - train_data[column].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AqiDataset(Dataset):\n",
    "    def __init__(self, data, history_len):\n",
    "        self.data = data\n",
    "        self.history_len = history_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        self.len = len(self.data) - self.history_len  \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_cols = ['pm2.5_normalized', 'amb_temp_normalized', 'ch4_normalized', 'co_normalized', 'nmhc_normalized']\n",
    "        y_cols = ['pm2.5_normalized']\n",
    "        x = self.data.iloc[index: index+self.history_len, :][x_cols].values\n",
    "        y = self.data.iloc[index+self.history_len, :][y_cols].values.astype('float')\n",
    "        x = torch.tensor(x).float()\n",
    "        y = torch.tensor(y).float()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5208\n",
      "torch.Size([48, 5]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# verify dataset instances\n",
    "temp_train_dataset = AqiDataset(train_data, history_len=48)\n",
    "print(len(temp_train_dataset))\n",
    "x, y = temp_train_dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 48, 5]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# train data_loader\n",
    "temp_train_data_loader = DataLoader(temp_train_dataset, batch_size=4)\n",
    "X, Y = next(iter(temp_train_data_loader))\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare the model\n",
    "- Initiate loss and optimization function\n",
    "- Training process\n",
    "- Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 48, 5])\n",
      "torch.Size([4, 1]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "temp_model = lstnet_gokul.LSTNet()\n",
    "\n",
    "for X, Y in temp_train_data_loader:\n",
    "    print(X.shape)\n",
    "    out = temp_model(X)\n",
    "    print(Y.shape, out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_len = 48\n",
    "batch_size = 8 \n",
    "\n",
    "epochs = 10\n",
    "\n",
    "lr = 0.01\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare different scenarios\n",
    "    - [x] number of epochs --> [50, 100, 200]\n",
    "    - [x] lookback periods --> [24, 24*2, 24*7, 24*30]\n",
    "    - [x] batch size --> [16, 64, 128]\n",
    "    - [x] loss function --> [MSE (nn.MSELoss()), MAE (nn.L1Loss()), Huber Loss (nn.SmoothL1Loss())]\n",
    "- Log the experiment\n",
    "- Monitor the result with MLFlow or ~~tensorboard~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [10, 20, 50]\n",
    "lookback_periods = [24//2, 24, 24*2, 24*7]\n",
    "batch_sizes = [16, 64, 128]\n",
    "loss_functions = [nn.MSELoss(), nn.SmoothL1Loss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the best model\n",
    "- Prepare the test data\n",
    "- Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
