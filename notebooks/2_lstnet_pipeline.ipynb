{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from tqdm.auto import tqdm\n",
    "from dateutil import parser\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 42])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand([4, 48, 5]) # [batch_size, time_steps, num_features]\n",
    "\n",
    "batch_size = X.size(0)\n",
    "\n",
    "C = X.unsqueeze(1) # [batch_size, num_channels=1, time_steps, num_features]\n",
    "C = F.relu(\n",
    "    nn.Conv2d(1, 32,kernel_size=(7, 5))(C)\n",
    "    ) # [batch_size, conv1_out_channels, shrinked_time_steps, 1]\n",
    "C = nn.Dropout(p = 0.2)(C)\n",
    "C = torch.squeeze(C, 3) # [batch_size, conv1_out_channels, shrinked_time_steps]\n",
    "\n",
    "C.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrinked_time_steps = C.size(2)\n",
    "shrinked_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = C.permute(0, 2, 1) # [batch_size, shrinked_time_steps, conv1_out_channels]\n",
    "out, hidden = nn.GRU(32, 64, batch_first=True)(R) # [batch_size, shrinked_time_steps, recc_out_channels]\n",
    "R = out[:, -1, :] # [batch_size, recc_out_channels]\n",
    "R = nn.Dropout(p = 0.2)(R)\n",
    "\n",
    "R.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: GRU(32, 4, batch_first=True), 1: GRU(32, 4, batch_first=True)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_reccs_out_channels = [4,4]\n",
    "skip_steps = [4,24]\n",
    "\n",
    "skip_reccs = {}\n",
    "for i, step in enumerate(skip_steps):\n",
    "    skip_reccs[i] = nn.GRU(32, skip_reccs_out_channels[i], batch_first=True)\n",
    "    \n",
    "skip_reccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 4 10\n",
      "torch.Size([4, 80])\n",
      "42 24 1\n",
      "torch.Size([4, 176])\n"
     ]
    }
   ],
   "source": [
    "for i, step in enumerate(skip_steps):\n",
    "    # print(i,step)\n",
    "    skip_step = step\n",
    "    skip_sequence_len = shrinked_time_steps // skip_step # self.pt\n",
    "    print(shrinked_time_steps, skip_step, skip_sequence_len)\n",
    "    \n",
    "    # shrinked_time_steps shrinked further\n",
    "    S = C[:, :, -skip_sequence_len*skip_step:] # [batch_size, conv1_out_channels, shrinked_time_steps]\n",
    "    S = S.view(S.size(0), S.size(1), skip_sequence_len, skip_step) # [batch_size, conv1_out_channels, skip_sequence_len, skip_step=num_skip_components]\n",
    "    # note that num_skip_components = skip_step\n",
    "    S = S.permute(0, 3, 2, 1).contiguous() # [batch_size, skip_step=num_skip_components, skip_sequence_len, conv1_out_channels]\n",
    "    S = S.view(S.size(0)*S.size(1), S.size(2), S.size(3))  # [batch_size*num_skip_components, skip_sequence_len, conv1_out_channels]\n",
    "    out, hidden = skip_reccs[i](S) # [batch_size*num_skip_components, skip_sequence_len, skip_reccs_out_channels[i]]\n",
    "    S = out[:, -1, :] # [batch_size*num_skip_components, skip_reccs_out_channels[i]]\n",
    "    S = S.view(batch_size, skip_step*S.size(1)) # [batch_size, num_skip_components*skip_reccs_out_channels[i]]\n",
    "    S = nn.Dropout(p = 0.2)(S)\n",
    "    R = torch.cat((R, S), 1) # [batch_size, recc_out_channels + skip_reccs_out_channels * num_skip_components]\n",
    "    \n",
    "    print(R.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Layer\n",
    "O = F.relu(nn.Linear(\n",
    "    64 + np.dot(skip_steps, skip_reccs_out_channels),\n",
    "    1)(R)) # [batch_size, output_out_features=1]\n",
    "O.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "AR = X[:, -7:, 3:4] # [batch_size, ar_window_size, output_out_features=1]\n",
    "AR = AR.permute(0, 2, 1).contiguous() # [batch_size, output_out_features, ar_window_size]\n",
    "AR = nn.Linear(7, 1)(AR) # [batch_size, output_out_features, 1]\n",
    "AR = AR.squeeze(2) # [batch_size, output_out_features]\n",
    "O = O + AR\n",
    "\n",
    "print(AR.size())\n",
    "print(O.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4087],\n",
       "        [-0.2802],\n",
       "        [-0.1295],\n",
       "        [-0.0511]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helper_functions import epa_taiwan_data_pipeline\n",
    "from models import lstnet_gokul, lstnet_laigoukun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = pathlib.Path(os.getcwd()).parent\n",
    "raw_data_dir = root_dir / \"data/0_raw\"\n",
    "processed_data_dir = root_dir / \"data/1_processed\"\n",
    "experiment_dir = root_dir / \"experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the data\n",
    "- Feature engineering\n",
    "- Turn the data into tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "site_name = \"Banqiao\"\n",
    "columns = [\"SiteEngName\",\"PM2.5\",\"AMB_TEMP\",\"CH4\",'CO',\"NMHC\",\"read_time\"]\n",
    "\n",
    "# import data\n",
    "pm25_df = epa_taiwan_data_pipeline.import_epa_data(site_name=site_name, year=year)[columns]\n",
    "\n",
    "# basic preprocessing\n",
    "pm25_df = epa_taiwan_data_pipeline.standardize_df(pm25_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data length:8760 \n",
      "Train data length:5256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteengname</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>amb_temp</th>\n",
       "      <th>ch4</th>\n",
       "      <th>co</th>\n",
       "      <th>nmhc</th>\n",
       "      <th>read_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399077</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2018-08-07 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399153</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2018-08-07 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399229</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2018-08-07 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399305</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2018-08-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399381</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2018-08-07 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       siteengname  pm2.5  amb_temp  ch4    co  nmhc           read_time\n",
       "399077     Banqiao   11.0      31.4  1.8  0.41  0.13 2018-08-07 19:00:00\n",
       "399153     Banqiao   11.0      30.8  1.8  0.35  0.10 2018-08-07 20:00:00\n",
       "399229     Banqiao   10.0      30.4  1.8  0.31  0.09 2018-08-07 21:00:00\n",
       "399305     Banqiao    8.0      30.2  1.8  0.30  0.08 2018-08-07 22:00:00\n",
       "399381     Banqiao    9.0      29.9  1.8  0.23  0.06 2018-08-07 23:00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = 0.6\n",
    "\n",
    "train_data = pm25_df.iloc[:int(len(pm25_df)*train_split),:]\n",
    "print(f\"All data length:{len(pm25_df)} \\nTrain data length:{len(train_data)}\")\n",
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_columns = ['pm2.5', 'amb_temp', 'ch4', 'co', 'nmhc']\n",
    "\n",
    "for column in normalized_columns:\n",
    "    normalized_column_name = column + '_normalized'\n",
    "    train_data[normalized_column_name] = (train_data[column] - train_data[column].min()) / (train_data[column].max() - train_data[column].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AqiDataset(Dataset):\n",
    "    def __init__(self, data, history_len):\n",
    "        self.data = data\n",
    "        self.history_len = history_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        self.len = len(self.data) - self.history_len  \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_cols = ['pm2.5_normalized', 'amb_temp_normalized', 'ch4_normalized', 'co_normalized', 'nmhc_normalized']\n",
    "        y_cols = ['pm2.5_normalized']\n",
    "        x = self.data.iloc[index: index+self.history_len, :][x_cols].values\n",
    "        y = self.data.iloc[index+self.history_len, :][y_cols].values.astype('float')\n",
    "        x = torch.tensor(x).float()\n",
    "        y = torch.tensor(y).float()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5208\n",
      "torch.Size([48, 5]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# verify dataset instances\n",
    "temp_train_dataset = AqiDataset(train_data, history_len=48)\n",
    "print(len(temp_train_dataset))\n",
    "x, y = temp_train_dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 48, 5]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# train data_loader\n",
    "temp_train_data_loader = DataLoader(temp_train_dataset, batch_size=4)\n",
    "X, Y = next(iter(temp_train_data_loader))\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare the model\n",
    "- Initiate loss and optimization function\n",
    "- Training process\n",
    "- Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 48, 5])\n",
      "torch.Size([4, 1]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "temp_model = lstnet_gokul.LSTNet()\n",
    "\n",
    "for X, Y in temp_train_data_loader:\n",
    "    print(X.shape)\n",
    "    out = temp_model(X)\n",
    "    print(Y.shape, out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_len = 48\n",
    "batch_size = 8 \n",
    "\n",
    "epochs = 10\n",
    "\n",
    "lr = 0.01\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare different scenarios\n",
    "    - [x] number of epochs --> [50, 100, 200]\n",
    "    - [x] lookback periods --> [24, 24x2, 24x7, 24x30] (history_len)\n",
    "    - [x] batch size --> [16, 64, 128]\n",
    "    - [x] loss function --> [MSE (nn.MSELoss()), MAE (nn.L1Loss()), Huber Loss (nn.SmoothL1Loss())]\n",
    "- Log the experiment\n",
    "- Monitor the result with MLFlow or ~~tensorboard~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [10, 20, 50]\n",
    "lookback_periods = [24//2, 24, 24*2, 24*7]\n",
    "batch_sizes = [16, 64, 128]\n",
    "loss_functions = [nn.MSELoss(), nn.SmoothL1Loss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the best model\n",
    "- Prepare the test data\n",
    "- Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
