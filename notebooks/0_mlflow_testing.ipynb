{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from tqdm.auto import tqdm\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from flexitext import flexitext\n",
    "# import seaborn as sns\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helper_functions import epa_taiwan_data_pipeline, engine\n",
    "from models import lstnet_gokul, lstnet_laigoukun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed to 420\n",
    "pl.seed_everything(420)\n",
    "\n",
    "device = \"cpu\"\n",
    "# device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = pathlib.Path(os.getcwd()).parent\n",
    "raw_data_dir = root_dir / \"data/0_raw\"\n",
    "processed_data_dir = root_dir / \"data/1_processed\"\n",
    "experiment_dir = root_dir / \"experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the data\n",
    "- Feature engineering\n",
    "- Turn the data into tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "site_name = \"Banqiao\"\n",
    "columns = [\"SiteEngName\",\"PM2.5\",\"AMB_TEMP\",\"CH4\",'CO',\"NMHC\",\"read_time\"]\n",
    "\n",
    "# import data\n",
    "pm25_df = epa_taiwan_data_pipeline.import_epa_data(site_name=site_name, year=year)[columns]\n",
    "\n",
    "# basic preprocessing\n",
    "pm25_df = epa_taiwan_data_pipeline.standardize_df(pm25_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_df_norm(\n",
    "    df:pd.DataFrame,\n",
    "    target:str='pm2.5',\n",
    "    cols:List=['pm2.5', 'amb_temp', 'ch4', 'co', 'nmhc']\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"do a normalization to a dataframe\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to be normalized\n",
    "        target (str, optional): the target to be predicted later. Defaults to 'pm2.5'.\n",
    "        cols (List, optional): columns that will be normalized. Defaults to ['pm2.5', 'amb_temp', 'ch4', 'co', 'nmhc'].\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, float, float]: return the normalized df and min and max value of the target\n",
    "    \"\"\"\n",
    "    normalized_column_names = []\n",
    "    for column in cols:\n",
    "        normalized_column_name = column + '_normalized'\n",
    "        normalized_column_names.append(normalized_column_name)\n",
    "        df[normalized_column_name] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "        # max_column_name = column + '_max'\n",
    "        # df[max_column_name] = df[column].max()\n",
    "        # min_column_name = column + '_min'\n",
    "        # df[min_column_name] = df[column].min()\n",
    "\n",
    "    return df, normalized_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data length:8760 \n",
      "Train data length:5256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteengname</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>amb_temp</th>\n",
       "      <th>ch4</th>\n",
       "      <th>co</th>\n",
       "      <th>nmhc</th>\n",
       "      <th>read_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399305</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2018-08-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399381</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2018-08-07 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       siteengname  pm2.5  amb_temp  ch4    co  nmhc           read_time\n",
       "399305     Banqiao    8.0      30.2  1.8  0.30  0.08 2018-08-07 22:00:00\n",
       "399381     Banqiao    9.0      29.9  1.8  0.23  0.06 2018-08-07 23:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_split = 0.6\n",
    "\n",
    "train_data = pm25_df.iloc[:int(len(pm25_df)*train_split),:]\n",
    "print(f\"All data length:{len(pm25_df)} \\nTrain data length:{len(train_data)}\")\n",
    "train_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteengname</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>amb_temp</th>\n",
       "      <th>ch4</th>\n",
       "      <th>co</th>\n",
       "      <th>nmhc</th>\n",
       "      <th>read_time</th>\n",
       "      <th>pm2.5_normalized</th>\n",
       "      <th>amb_temp_normalized</th>\n",
       "      <th>ch4_normalized</th>\n",
       "      <th>co_normalized</th>\n",
       "      <th>nmhc_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.080605</td>\n",
       "      <td>0.049020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Banqiao</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.277397</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.080605</td>\n",
       "      <td>0.053922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   siteengname  pm2.5  amb_temp  ch4    co  nmhc           read_time  \\\n",
       "1      Banqiao   20.0      16.1  1.9  0.37  0.07 2018-01-01 00:00:00   \n",
       "77     Banqiao   19.0      16.2  1.9  0.37  0.08 2018-01-01 01:00:00   \n",
       "\n",
       "    pm2.5_normalized  amb_temp_normalized  ch4_normalized  co_normalized  \\\n",
       "1           0.226190             0.273973        0.214286       0.080605   \n",
       "77          0.214286             0.277397        0.214286       0.080605   \n",
       "\n",
       "    nmhc_normalized  \n",
       "1          0.049020  \n",
       "77         0.053922  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_columns = ['pm2.5', 'amb_temp', 'ch4', 'co', 'nmhc']\n",
    "\n",
    "train_data, normalized_column_names = min_max_df_norm(train_data)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5208\n",
      "torch.Size([48, 1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# verify dataset instances\n",
    "temp_train_dataset = epa_taiwan_data_pipeline.AqiDataset(\n",
    "    train_data,\n",
    "    history_len=48,\n",
    "    col_names=[normalized_column_names[0]],\n",
    "    device=device\n",
    ")\n",
    "print(len(temp_train_dataset))\n",
    "x, y = temp_train_dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 48, 1]) torch.Size([4, 1])\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "# train data_loader\n",
    "temp_train_data_loader = DataLoader(temp_train_dataset, batch_size=4)\n",
    "X, Y = next(iter(temp_train_data_loader))\n",
    "print(X.shape, Y.shape)\n",
    "print(X.is_cuda, Y.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "temp_model = lstnet_gokul.LSTNet(\n",
    "    ar_window_size=48,\n",
    "    num_features=1,\n",
    "    recc1_out_channels=64,\n",
    "    conv1_out_channels=32\n",
    ")\n",
    "# temp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 48, 1])\n",
      "torch.Size([4, 1]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in temp_train_data_loader:\n",
    "    print(X.shape)\n",
    "    out = temp_model(X.to(device))\n",
    "    print(Y.shape, out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow experiment testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.6\n",
    "\n",
    "history_len = 48\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651\n",
      "torch.Size([8, 48, 1]) torch.Size([8, 1])\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "normalized_columns = ['pm2.5', 'amb_temp', 'ch4', 'co', 'nmhc']\n",
    "\n",
    "train_data, normalized_column_names = min_max_df_norm(train_data)\n",
    "\n",
    "train_dataset = epa_taiwan_data_pipeline.AqiDataset(\n",
    "    train_data, \n",
    "    history_len=history_len, \n",
    "    col_names=[normalized_column_names[0]], \n",
    "    device=None)\n",
    "\n",
    "# train data_loader\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "X, Y = next(iter(train_data_loader))\n",
    "print(len(train_data_loader))\n",
    "print(X.shape, Y.shape)\n",
    "print(X.is_cuda, Y.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n"
     ]
    }
   ],
   "source": [
    "test_data = pm25_df.iloc[int(len(pm25_df)*train_split):,:]\n",
    "\n",
    "test_data, _ = min_max_df_norm(test_data)\n",
    "\n",
    "test_dataset = epa_taiwan_data_pipeline.AqiDataset(\n",
    "    test_data,\n",
    "    history_len=history_len,\n",
    "    col_names=[normalized_column_names[0]],\n",
    "    device=None)\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(len(test_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstnet_gokul.LSTNet(\n",
    "    ar_window_size=24,\n",
    "    num_features=1,\n",
    "    recc1_out_channels=64,\n",
    "    conv1_out_channels=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 0.01\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(temp_model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the experiment name\n",
    "# timestamp = datetime.now().strftime(\"%Y_%m_%d\") # returns current date in YYYY-MM-DD format\n",
    "\n",
    "# try:\n",
    "#     mlflow.set_experiment(f\"{timestamp}\")\n",
    "# except:\n",
    "#     os.mkdir(\"mlruns\")\n",
    "#     mlflow.set_experiment(f\"{timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment name\n",
    "experiment_name = datetime.now().strftime(\"%Y_%m_%d\") # returns current date in YYYY-MM-DD format\n",
    "\n",
    "# Check if the experiment exists, and if not, create it\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "# MLFLOW_TRACKING_URI=https://dagshub.com/amrirasyidi/air_quality_forecasting.mlflow \\\n",
    "# MLFLOW_TRACKING_USERNAME=amrirasyidi \\\n",
    "# MLFLOW_TRACKING_PASSWORD=a2c9e1ebaf6ce8285a9cced5e2c757c386254b7a \\\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'amrirasyidi'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'a2c9e1ebaf6ce8285a9cced5e2c757c386254b7a'\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow.get_experiment_by_name(experiment_name).experiment_id):\n",
    "    # Define your training loop\n",
    "    epoch_avg_train_loss, epoch_avg_test_loss = engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_data_loader,\n",
    "        test_dataloader=test_data_loader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=criterion,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    print(\"LSTNET model (learning_rate={:f}, batch_size={:f}):\".format(lr, batch_size))\n",
    "    print(\"  Epoch average training loss: %s\" % epoch_avg_train_loss)\n",
    "    print(\"  Epoch average test loss: %s\" % epoch_avg_test_loss)\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\"learning_rate\": lr, \"batch_size\": batch_size})\n",
    "\n",
    "    # Log metrics during training\n",
    "    mlflow.log_metrics(\n",
    "        {\"train_loss\": epoch_avg_train_loss[0], \"test_loss\": epoch_avg_test_loss[0]},\n",
    "        # step=epoch\n",
    "    )\n",
    "\n",
    "    # # Log additional artifacts\n",
    "    # mlflow.log_artifact(\"path/to/your/training_plots.png\")\n",
    "\n",
    "    ## For Remote server only (DAGShub)\n",
    "\n",
    "    remote_server_uri=\"https://dagshub.com/amrirasyidi/air_quality_forecasting.mlflow\"\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "        # Register the model\n",
    "        # There are other ways to use the Model Registry, which depends on the use case,\n",
    "        # please refer to the doc for more information:\n",
    "        # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "        mlflow.pytorch.log_model(\n",
    "            model, \"temp_model\", registered_model_name=\"test_model\"\n",
    "        )\n",
    "    else:\n",
    "        mlflow.pytorch.log_model(model, \"temp_model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
